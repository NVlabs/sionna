{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e6b8cc",
   "metadata": {},
   "source": [
    "# To Add\n",
    "\n",
    "- base room .xml à ajouter au scene de Sionna\n",
    "- accéder aux SceneObject depuis les AssetObject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a8731",
   "metadata": {},
   "source": [
    "# Introduction to Sionna RT - Scene and Assets Configuration Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702817e",
   "metadata": {},
   "source": [
    "In this notebook, you will\n",
    "- Learn how to programaticaly append or remove assets object to a scene (without using Blender).\n",
    "- See the impact of the assets within the scene w.r.t. ray-traced channels for link-level simulations instead of stochastic channel models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0a988",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Information On Assets](#Information-On-Assets)\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32f3d7",
   "metadata": {},
   "source": [
    "## Information On Assets\n",
    "\n",
    "It is usefull to be able to construct a scene dynamically by adding and removing objects, referred to as assets, thus being able to automatically generate datasets from the scenes and/or define complex scenario. To this end, we propose a few novel functionalities. One can define a scene, e.g. using Blender, import the scene within Sionna and then add new assets to that scene. The assets can also be separately defined in Blender for instance. As an example, one could define a scene with a car park, and append to that scene a varing number of cars to see the impact in terms of RF propagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938106f2",
   "metadata": {},
   "source": [
    "## GPU Configuration and Imports <a class=\"anchor\" id=\"GPU-Configuration-and-Imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c23abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_num = 0 # Use \"\" to use the CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Colab does currently not support the latest version of ipython.\n",
    "# Thus, the preview does not work in Colab. However, whenever possible we\n",
    "# strongly recommend to use the scene preview mode.\n",
    "try: # detect if the notebook runs in Colab\n",
    "    import google.colab\n",
    "    colab_compat = True # deactivate preview\n",
    "except:\n",
    "    colab_compat = False\n",
    "resolution = [480,320] # increase for higher quality of renderings\n",
    "\n",
    "# Allows to exit cell execution in Jupyter\n",
    "class ExitCell(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# Avoid warnings from TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "tf.random.set_seed(1) # Set global random seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b7d49",
   "metadata": {},
   "source": [
    "# To Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34147eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Import Sionna RT components\n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera, AssetObject\n",
    "\n",
    "# For link-level simulations\n",
    "from sionna.channel import cir_to_time_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\n",
    "from sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\n",
    "from sionna.utils import compute_ber, ebnodb2no, PlotBER\n",
    "from sionna.ofdm import KBestDetector, LinearDetector\n",
    "from sionna.mimo import StreamManagement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58380340",
   "metadata": {},
   "source": [
    "## Loading Scenes\n",
    "\n",
    "The Sionna RT module can either load external scene files (in Mitsuba's XML file format) or it can load one of the [integrated scenes](https://nvlabs.github.io/sionna/api/rt.html#example-scenes).\n",
    "\n",
    "In this example, we load a scene containing a floor and a basic wall above it. The scene can be seen as a the static reference, in which one can add or remove assets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66aa238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load scene\n",
    "scene = load_scene(filename=sionna.rt.scene.floor_wall)\n",
    "\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512);\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec6563",
   "metadata": {},
   "source": [
    "## Load and Handle Assets\n",
    "\n",
    "In a static scene, one can add assets at various position to evaluate different scenario without having to design a dedicated scene beforehand. It should be noted, that assets are added to the scene by recreating the scene from scratch (reloading the scene). Hence, the action to add or remove an asset object to a scene is not differentiable, but the previous and the novel scenes preserve their differentiability properties as any scene in Sionna. This tool must be seen as a way to programmatically construct the scene, e.g. to generate many random scenes to construct a dataset for neural networks training.\n",
    "\n",
    "Some assets are located in ./sionna/rt/assets. Let's see how to load and use them.\n",
    "\n",
    "NB: As a workaround to maintain differentiability when placing an object, one could use the mobility tools from Sionna to move pre-existing objects of the scene into or out of the zone of interest of the scene. Yet, this would require to have put these objects in the scene in the first place.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48401ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an asset\n",
    "body_asset = AssetObject(name=\"asset_0\", filename=sionna.rt.asset_object.body)\n",
    "\n",
    "# Alternative call\n",
    "# body_asset = AssetObject(name=\"asset_0\", filename=\"./sionna/rt/assets/body/body.xml\")\n",
    "\n",
    "# Add the asset to the scene\n",
    "scene.add(body_asset)\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66efde2",
   "metadata": {},
   "source": [
    "As it can be seen in the preview, a body has been added to the previous scene, by creating a novel scene from scratch.\n",
    "\n",
    "The body can be handle in the same way as any object of the scene.\n",
    "\n",
    "It is listed in the .asset_objects method from the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the assets dictionnary from the scene\n",
    "print(scene.asset_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed615dbd",
   "metadata": {},
   "source": [
    "The dictionnary contains all the assets from the scene.\n",
    "\n",
    "Our body \"asset_0\" is listed as an AssetObject. They are slithly different from others Sionna's SceneObject, as we will demonstrate in this notebook. \n",
    "\n",
    "First of all, AssetObject can be composed of several SceneObject. Use the method .shapes to display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the asset object by name as any object from the scene\n",
    "body_asset = scene.get('asset_0')\n",
    "\n",
    "# Print the objects (SceneObject) composing the asset (AssetObject)\n",
    "print(f\"Check the type of the variable: {type(body_asset).__name__}\")\n",
    "print(f\"{body_asset.shapes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c024452",
   "metadata": {},
   "source": [
    "Our asset (AssetObject) \"asset_0\" is composed of one object (SceneObject) \"asset_0_body\".\n",
    "\n",
    "The name of the object is based on the asset name \"asset_0\" associated with the component name defined in Blender \"body\".\n",
    "\n",
    "This SceneObject can also be seen in the object dictionnary of the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a dictionnary containing all the objects of the scene\n",
    "print(scene.objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0454e3",
   "metadata": {},
   "source": [
    "The scene contains three objects:\n",
    "- The \"floor\" that was in the basic scene.\n",
    "- The \"wall\" that was also in the basic scene.\n",
    "- The \"body\", named \"asset_0_body\", that we have added.\n",
    "\n",
    "Hence, the body is seen as a classic SceneObject by Sionna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a595116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the body object from the scene as any SceneObject\n",
    "body_object = scene.get('asset_0_body')\n",
    "\n",
    "\n",
    "print(f\"Current body asset position: {body_asset.position.numpy()}\")\n",
    "print(f\"Current body asset orientation: {body_asset.orientation.numpy()}\")\n",
    "# print(f\"Current body asset velocity: {body_asset.velocity.numpy()}\")\n",
    "\n",
    "print(f\"Current body object position: {body_object.position.numpy()}\")\n",
    "print(f\"Current body object orientation: {body_object.orientation.numpy()}\")\n",
    "print(f\"Current body object velocity: {body_object.velocity.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350a446",
   "metadata": {},
   "source": [
    "The asset also exposes the usual attributes \"position\", \"orientation\" and \"velocity\".\n",
    "\n",
    "As it can be seen, the position of the object is not [0.,0.,0.], contrary to the asset one. This is because Sionna creates a virtual rectangular Axis-Aligned Bounding Box (AABB) around the whole asset and return the position of the barycenter of this box. Hence, the position is somewhere at the center of the body. The asset barycenter is the one defined originally in Blender, at the feet. To witness that behavior, we can simply fix the position of the object to [0.,0.,0.] using the SceneObject property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77bbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the original position\n",
    "original_body_object_position = body_object.position.numpy()\n",
    "\n",
    "# Manually set the SceneObject position\n",
    "body_object.position = [0.,0.,0.]\n",
    "\n",
    "print(f\"Current body object position: {body_object.position.numpy()}\")\n",
    "print(f\"Current body asset position: {body_asset.position.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f176595",
   "metadata": {},
   "source": [
    "The hit box barycenter of our asset is now at the coordinates [0.,0.,0.]. The position (and other attributes like orientation and velocity) of the asset is not automatically modified when modifying a component object. The reason behind this design choice is explained in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f72725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set the orientation of the SceneObject\n",
    "body_object.orientation = [np.pi/4.,np.pi/4.,np.pi/4.]\n",
    "\n",
    "print(f\"Orientation of the object: {body_object.orientation.numpy()}\")\n",
    "print(f\"Position of the object: {body_object.position.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089ce69",
   "metadata": {},
   "source": [
    "After the change of orientation of the SceneObject, the position of the barycenter of the object has changed. That is because Sionna's AABB is not rotated, but recomputed with edges parallel to the coordinate reference axis (x,y,z), hence modifying the barycenter position.\n",
    "\n",
    "That's why we advice to directly manipulate the asset itself, as you will be able to conveniently and consistently manipulate group of objects together. Also, this is more natural, as the origin of the asset is defined by the user through the asset generation in Blender.\n",
    "\n",
    "This is also the reason why modifying the position/orientation/velocity of an object from an asset will not modify the asset's configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that the position and orientation of the asset has not been modified\n",
    "print(f\"Position of the asset: {body_asset.position.numpy()}\")\n",
    "print(f\"Orientation of the asset: {body_asset.orientation.numpy()}\")\n",
    "\n",
    "# Position the body at its original position, with original orientation\n",
    "# First set the orientation and then the position to avoid side effect\n",
    "body_object.orientation = [0.,0.,0.]\n",
    "body_object.position = original_body_object_position\n",
    "\n",
    "print(f\"Position of the object: {body_object.position.numpy()}\")\n",
    "print(f\"Orientation of the object: {body_object.orientation.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439316de",
   "metadata": {},
   "source": [
    "The body is back on its feet! Now let's move it to one side of the wall using the asset properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d0d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the body to one side of the wall\n",
    "body_asset.position = [1.,0.,0.]\n",
    "\n",
    "print(f\"Position of the asset: {body_asset.position.numpy()}\")\n",
    "print(f\"Orientation of the asset: {body_asset.orientation.numpy()}\")\n",
    "\n",
    "print(f\"Position of the object: {body_object.position.numpy()}\")\n",
    "print(f\"Orientation of the object: {body_object.orientation.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d0a92",
   "metadata": {},
   "source": [
    "The body object position has been correctly moved along with the asset one. Now let's change its orientation so it faces the wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the body face the wall\n",
    "body_asset.orientation = [-np.pi/2.,0.,0.]\n",
    "\n",
    "print(f\"Position of the asset: {body_asset.position.numpy()}\")\n",
    "print(f\"Orientation of the asset: {body_asset.orientation.numpy()}\")\n",
    "\n",
    "print(f\"Position of the object: {body_object.position.numpy()}\")\n",
    "print(f\"Orientation of the object: {body_object.orientation.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834379f7",
   "metadata": {},
   "source": [
    "The center of the body asset is located at its feet. So we can turn it upside down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91927d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the body upside down\n",
    "body_asset.orientation += [0.,np.pi,0.]\n",
    "\n",
    "print(f\"Position of the asset: {body_asset.position.numpy()}\")\n",
    "print(f\"Orientation of the asset: {body_asset.orientation.numpy()}\")\n",
    "\n",
    "print(f\"Position of the object: {body_object.position.numpy()}\")\n",
    "print(f\"Orientation of the object: {body_object.orientation.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ffed3",
   "metadata": {},
   "source": [
    "Now, let's add another asset body to the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffbe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second asset\n",
    "second_body_asset = AssetObject(name=\"asset_1\", filename=sionna.rt.asset_object.body)\n",
    "\n",
    "# Print body object memory address\n",
    "first_body_memory_address = hex(id(body_object))\n",
    "print(f\"Memory address of the first SceneObject: {first_body_memory_address}\")\n",
    "\n",
    "# Add it to the scene\n",
    "# Adding an asset with the same name than another asset would replace the previous asset with the new one\n",
    "scene.add(second_body_asset)\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0e763",
   "metadata": {},
   "source": [
    "Again, adding an asset to a scene will reload the scene from scratch. In particular, that means that all the objects from the scene are deleted and recreated.\n",
    "\n",
    "Here, the new \"asset_0_body\" object is corretly allocated back to the asset \"asset_0\", and the attributes (position/orientation/velocity/radio_material) from the original \"asset_0_body\" are transfered to the new one.\n",
    "\n",
    "The old \"asset_0_body\" is not connected to the scene anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79700f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_object_0 = scene.get(\"asset_0_body\")\n",
    "body_object_1 = scene.get(\"asset_1_body\")\n",
    "\n",
    "print(f\"Old memory address of the body_asset_0 SceneObject: {first_body_memory_address}\")\n",
    "print(f\"New memory address of the body_asset_0 SceneObject: {hex(id(body_object_0))}\")\n",
    "print(f\"Check the memory address of the asset object: {hex(id(body_asset.shapes['asset_0_body']))}\")\n",
    "\n",
    "# Check that the position of the asset_0 and the new asset_0_body object are set correctly\n",
    "print(body_asset.position.numpy())\n",
    "print(body_object_0.position.numpy())\n",
    "print(body_object.position.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb526bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position the second body, so that it mirror the first one\n",
    "second_body_asset.position = [1.,0.,0.]\n",
    "second_body_asset.orientation = [-np.pi/2,0.,0.]\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935109e",
   "metadata": {},
   "source": [
    "We can remove an asset from a scene.\n",
    "\n",
    "This will also reload the scene from scratch. The removed SceneObject(s) are no longer referenced. The AssetObject is not deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26debf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.remove(\"asset_0\")\n",
    "\n",
    "print(f\"Scene assets: {scene.asset_objects}\")\n",
    "print(f\"Scene objects: {scene.objects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(body_asset)\n",
    "print(body_asset.shapes)\n",
    "print(body_object_0)\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba238f",
   "metadata": {},
   "source": [
    "So now that we have play a little with a single body, let's use a two bodies asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the body asset\n",
    "scene.remove('asset_1')\n",
    "\n",
    "print(f\"Scene assets: {scene.asset_objects}\")\n",
    "print(f\"Scene objects: {scene.objects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27179342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an asset\n",
    "bodies_asset = AssetObject(name=\"asset_0\", filename=sionna.rt.asset_object.two_persons)\n",
    "\n",
    "# Add the asset to the scene\n",
    "scene.add(bodies_asset)\n",
    "\n",
    "print(f\"Scene assets: {scene.asset_objects}\")\n",
    "print(f\"Scene objects: {scene.objects}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e8a9f",
   "metadata": {},
   "source": [
    "Our asset is composed of two objects \"asset_0_person_1\" and \"asset_0_person_2\", as it can be seen in the objects list of the scene.\n",
    "\n",
    "We can use the asset properties to move the bodies around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get assets and objects\n",
    "body_1_object = scene.get('asset_0_person_1')\n",
    "body_2_object = scene.get('asset_0_person_2')\n",
    "\n",
    "# Move the two bodies to one side of the wall\n",
    "bodies_asset.position = [1.,0.,0.]\n",
    "\n",
    "print(f\"Position of the asset: {bodies_asset.position.numpy()}\")\n",
    "print(f\"Orientation of the asset: {bodies_asset.orientation.numpy()}\")\n",
    "\n",
    "print(f\"Position of the person 1 object: {body_1_object.position.numpy()}\")\n",
    "print(f\"Orientation of the person 1 object: {body_1_object.orientation.numpy()}\") \n",
    "\n",
    "print(f\"Position of the person 2 object: {body_2_object.position.numpy()}\")\n",
    "print(f\"Orientation of the person 2 object: {body_2_object.orientation.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a56ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the two bodies to each side of the wall\n",
    "bodies_asset.position = [0.,0.,0.]\n",
    "bodies_asset.orientation = [np.pi/2.,0.,0.]\n",
    "\n",
    "print(f\"Position of the asset: {bodies_asset.position.numpy()}\")\n",
    "print(f\"Orientation of the asset: {bodies_asset.orientation.numpy()}\")\n",
    "\n",
    "print(f\"Position of the person 1 object: {body_1_object.position.numpy()}\")\n",
    "print(f\"Orientation of the person 1 object: {body_1_object.orientation.numpy()}\") \n",
    "\n",
    "print(f\"Position of the person 2 object: {body_2_object.position.numpy()}\")\n",
    "print(f\"Orientation of the person 2 object: {body_2_object.orientation.numpy()}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324d2cb",
   "metadata": {},
   "source": [
    "Now we will demonstrate that the assets have the same interaction with ray tracing than any other Sionna SceneObject.\n",
    "\n",
    "We will add a TX/RX couple at each side of the wall.\n",
    "\n",
    "The bodies objects will be individually moved (again this is not recommended), so that we increase the space between them and can use them as reflectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the bodies\n",
    "bodies_asset.orientation = [0.,0.,0.]\n",
    "body_1_object.position += [0.,1.5,0.]\n",
    "body_2_object.position += [0.,-1.5,0.]\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the transmitter and receiver arrays\n",
    "scene.tx_array = PlanarArray(num_rows=1,\n",
    "                             num_cols=1,\n",
    "                             vertical_spacing=0.5,\n",
    "                             horizontal_spacing=0.5,\n",
    "                             pattern=\"iso\",\n",
    "                             polarization=\"V\")\n",
    "\n",
    "scene.rx_array = scene.tx_array\n",
    "\n",
    "# Add a transmitter and receiver with equal distance from the center of the surface\n",
    "# The position is set precisely to get perfect reflexion from the bodies hands\n",
    "scene.add(Transmitter(name=\"tx\", position=[-3.1,0.,2.1]))\n",
    "scene.add(Receiver(name=\"rx\", position=[3.1,0.,2.1]))\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the scene frequency\n",
    "scene.frequency = 2.4e9\n",
    "\n",
    "# No LOS, one reflection max\n",
    "paths = scene.compute_paths(los=False, reflection=True, max_depth=1, num_samples=1e6, method='exhaustive')\n",
    "\n",
    "print(f\"Amplitude of the paths: {np.abs(paths.a[0,0,0,0,0,1:,0].numpy())}\")\n",
    "print(f\"Delay of the paths: {paths.tau[0,0,0,1:].numpy()}\")\n",
    "\n",
    "# Open 3D preview (only works in Jupyter notebook)\n",
    "if colab_compat:\n",
    "    scene.render(\"scene-cam-0\", paths=paths);\n",
    "    raise ExitCell\n",
    "scene.preview(paths=paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8354ca2",
   "metadata": {},
   "source": [
    "The bodies provided in the asset are composed of numerous small reflective surfaces. The positions of TX and RX were chosen to obtain reflections on the hands.\n",
    "\n",
    "NB: To see more paths, one could activate the scattering.\n",
    "\n",
    "There are exactly 9 paths in the scene:\n",
    "* The first path to arrive is reflected on the floor.\n",
    "* The 8 other paths are reflected on the hands. You can zoom on the preview to see the 8 paths. Because of the symetry of the scene, these paths arrive at (almost) the same time with (almost) the same energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, tau = paths.cir()\n",
    "\n",
    "# Remove first null LOS path\n",
    "a = a[...,1:,:]\n",
    "tau = tau[...,1:]\n",
    "\n",
    "t = tau[0,0,0,:]/1e-9 # Scale to ns\n",
    "a_abs = np.abs(a)[0,0,0,0,0,:,0]\n",
    "a_max = np.max(a_abs)\n",
    "\n",
    "# Add dummy entry at start/end for nicer figure\n",
    "t = np.concatenate([(0.,), t, (np.max(t)*1.1,)])\n",
    "a_abs = np.concatenate([(np.nan,), a_abs, (np.nan,)])\n",
    "\n",
    "# And plot the CIR\n",
    "plt.figure()\n",
    "plt.title(\"Channel impulse response realization\")\n",
    "\n",
    "# plt.stem(t, a_abs)\n",
    "plt.stem(t, a_abs)\n",
    "plt.xlim([0, np.max(t)])\n",
    "plt.ylim([-2e-6, a_max*1.1])\n",
    "plt.xlabel(r\"$\\tau$ [ns]\")\n",
    "plt.ylabel(r\"$|a|$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fca0ec",
   "metadata": {},
   "source": [
    "On the CIR, we can see the 8 paths reflected by the hands arrived at the same time, around 2.45 ns. Generating the time channel estimate from the CIR should merge the power of these paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81eaeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the frequency response of the channel at frequencies.\n",
    "sampling_freq = 5e9 # 0.2 ns resolution\n",
    "l_min = -6\n",
    "l_max = 20\n",
    "h_time = cir_to_time_channel(bandwidth=sampling_freq, a=a, tau=tau, l_min=l_min, l_max=l_max, normalize=True)\n",
    "t_time = np.arange(l_min, (l_max+1), 1) * (1/sampling_freq)\n",
    "\n",
    "h_time_abs = np.abs(h_time[0,0,0,0,0,0,:].numpy())\n",
    "\n",
    "# And plot the CIR\n",
    "plt.figure()\n",
    "plt.title(\"Time Channel from CIR\")\n",
    "plt.stem(t_time, h_time_abs)\n",
    "plt.xlim([0, np.max(t_time)])\n",
    "# plt.ylim([-2e-6, a_max*1.1])\n",
    "plt.xlabel(r\"$\\tau$ [ns]\")\n",
    "plt.ylabel(r\"$|h_time|$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a0d31",
   "metadata": {},
   "source": [
    "Because of the 8 paths reflected by the hands, most of the energy arrive through these paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e94a4",
   "metadata": {},
   "source": [
    "# Material and BSDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f50fc0",
   "metadata": {},
   "source": [
    "In Sionna the materials of the scene objects are defined by a RadioMaterial.\n",
    "\n",
    "A RadioMaterial defines how the radio waves will interact with the object, thanks to attributes like permittivity, conductivity or scattering coefficient.\n",
    "\n",
    "Sionna defines some radio materials at initialization. All the radio materials currently defined and available can be exposed in the radio_materials dictionnary from the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scene.radio_materials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db559b",
   "metadata": {},
   "source": [
    "This does not mean that they are all used in the scene itself, but they are defined in Sionna.\n",
    "\n",
    "Each RadioMaterial has a name and can be allocated to a SceneObject. Also, we can check all the object with a given RadioMaterial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff441921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the radio material of each object of the scene\n",
    "for obj in list(scene.objects.values()):\n",
    "    print(f\"SceneObject {obj.name} is composed of {obj.radio_material.name}\")\n",
    "    \n",
    "# Get the objects using each material if any\n",
    "for rm in list(scene.radio_materials.values()):\n",
    "    obj_list = []\n",
    "    for obj_id in rm.using_objects:\n",
    "        for obj in list(scene.objects.values()):\n",
    "            if obj.object_id == obj_id:\n",
    "                obj_list.append(obj.name)\n",
    "    if len(obj_list) != 0:\n",
    "        print(f\"Material {rm.name} is used by {obj_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_1_object.radio_material = \"itu_brick\"\n",
    "\n",
    "print(f\"{body_1_object.name} is made of {body_1_object.radio_material.name}\")\n",
    "\n",
    "rm = scene.get(\"itu_brick\") # get RadioMaterial\n",
    "obj_list = []\n",
    "for obj_id in rm.using_objects:\n",
    "    for obj in list(scene.objects.values()):\n",
    "        if obj.object_id == obj_id:\n",
    "            obj_list.append(obj.name)\n",
    "if len(obj_list) != 0:\n",
    "    print(f\"Material {rm.name} is used by {obj_list}\")\n",
    "    \n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73679a",
   "metadata": {},
   "source": [
    "As you can see, the visual aspect of the first body is still in marble and has not been updated. Changing the radio material of an object do not change the way it is rendered in the scene.\n",
    "\n",
    "To change it, we need to reload the scene manually. It should be noted that RadioMaterial is correctly set and would affect the paths as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the impact on the paths\n",
    "paths = scene.compute_paths(los=False, reflection=True, max_depth=1, num_samples=1e6, method='exhaustive')\n",
    "\n",
    "print(f\"Amplitude of the paths: {np.abs(paths.a[0,0,0,0,0,1:,0].numpy())}\")\n",
    "print(f\"Delay of the paths: {paths.tau[0,0,0,1:].numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be1008",
   "metadata": {},
   "source": [
    "The paths with amplitude 4.7e-4 bounced on the brick person (first body), and the ones with amplitude 5.7e-4 bounced on the marble person (second body)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f81dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually reload the scene to change the renderring\n",
    "scene.reload_scene()\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a933d7",
   "metadata": {},
   "source": [
    "The positions of the objects are maintained after the reload. The first body is correctly displayed as a brick object.\n",
    "\n",
    "The RadioMaterial class does not defined itself how it should be rendered. This is handle by the BSDF class, associated to it.\n",
    "\n",
    "A single BSDF is affected to each RadioMaterial defined in Sionna (scene.radio_materials).\n",
    "\n",
    "At initialization, the BSDF is defined as random. It is said to be \"placeholder\". Hence one can use any pre-defined RadioMaterial without specifying the BSDF, but we advice to define a proper custom BSDF before that.\n",
    "\n",
    "The definition of the BSDF can be done manually, or directly through the .xml file of the scene or an asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013003e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a RadioMaterial defined in the scene\n",
    "rm = scene.get(\"itu_metal\")\n",
    "\n",
    "# Shof the BSDF object associated to it\n",
    "print(f\"The BSDF object describing the itu_metal rendering: {rm.bsdf}\")\n",
    "print(f\"The RGB corresponding triplet: {rm.bsdf.rgb}\")\n",
    "\n",
    "# Set the first body radio material to itu_metal\n",
    "body_1_object.radio_material = \"itu_metal\"\n",
    "\n",
    "# Manually reload the scene to change the renderring\n",
    "scene.reload_scene()\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if BSDF is placeholder\n",
    "print(f\"At initialization, is the BSDF placeholder: {rm.bsdf.is_placeholder}\")\n",
    "\n",
    "# Setting the RGB of a BSDF triggers a reload scene to update the rendering\n",
    "rm.bsdf.rgb = [127./255.,1.,0.] # chartreuse\n",
    "\n",
    "# Check if BSDF is placeholder\n",
    "print(f\"After setting the RGB, is the BSDF placeholder: {rm.bsdf.is_placeholder}\")\n",
    "\n",
    "# Preview the scene\n",
    "if colab_compat:\n",
    "    scene.render(camera=\"scene-cam-0\", num_samples=512)\n",
    "    raise ExitCell\n",
    "scene.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d4970",
   "metadata": {},
   "source": [
    "When you add an asset, each shape, a.k.a SceneObject, is associated with radio material and a BSDF, described in the .xml file of the asset.\n",
    "\n",
    "Adding the asset to the scene can trigger three basic behavior:\n",
    "* The radio material name is not currently registered in the scene. A new radio material is added to the scene with the same name, the corresponding BSDF. You still had to specify the radio material attributes for interaction with radio waves.\n",
    "* The radio material name already exist in the scene. The shapes will be associated with the pre-existing radio material. Regarding the BSDF, if it is a placeholder one, then it will be automatically replaced by the one the .xml file. Otherwise, the standard behavior is to keep the one already specify in the scene radio material.\n",
    "* To force an overwrite of the existing BSDF with the one provided in the .xml of the asset, you can set overwrite_scene_bsdfs to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b427258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a relevant cell here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7fa4f",
   "metadata": {},
   "source": [
    "One important property of radio materials and associated BSDFs, is that the only usable references are the one provided in the scene.radio_materials dictionnary.\n",
    "\n",
    "You can update the attributes of the RadioMaterial object obtained from the dictionnary but not replace the RadioMaterial.\n",
    "\n",
    "Replacing the RadioMaterial involve reloading the scene to correctly assign the new RadioMaterial object to the relevant SceneObject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d857955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a relevant cell here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16500743",
   "metadata": {},
   "source": [
    "It is also possible to assign a RadioMaterial to an AssetObject.\n",
    "\n",
    "This means that all the shapes from the asset will be assigned this RadioMaterial. \n",
    "\n",
    "The RadioMaterial can be provided as a string, but is should be present in the scene radio materials dictionnary, or as a complete RadioMaterial object.\n",
    "\n",
    "Three cases are possible:\n",
    "* The RadioMaterial name does not exist in the scene. It is added to the scene, when the asset is added.\n",
    "* The RadioMaterial name is already present in the scene. The standard behavior is to not overwrite the existing object. which is assigned to the asset component SceneObject. The provided RadioMaterial is discarded.\n",
    "* To force an overwrite of the existing RadioMaterial of the scene, you can set overwrite_scene_radio_materials to True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80096243",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion and Outlook"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
