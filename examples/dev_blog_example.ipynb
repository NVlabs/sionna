{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01e3f8f",
   "metadata": {},
   "source": [
    "# “Hello, Sionna!\"\n",
    "\n",
    "The following notebook implements the “Hello, Sionna!” example from the [Sionna whitepaper](https://arxiv.org/pdf/2203.11854.pdf) and the [NVIDIA blog post](https://developer.nvidia.com/blog/jumpstarting-link-level-simulations-with-sionna/). \n",
    "The transmission of a batch of LDPC codewords over an AWGN channel using 16QAM modulation is simulated. This example shows how Sionna layers are instantiated and applied to a previously defined tensor. The coding style follows the [functional API](https://www.tensorflow.org/guide/keras/functional) of Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f9e3c",
   "metadata": {},
   "source": [
    "The [official documentation](https://nvlabs.github.io/sionna) provides key material on how to use Sionna and how its components are implemented.\n",
    "Many more [tutorials](https://nvlabs.github.io/sionna/tutorials.html) are available online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7121a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_num = 0 # Use \"\" to use the CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "    \n",
    "# IPython \"magic function\" for inline plots\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import required Sionna components\n",
    "from sionna.mapping import Constellation, Mapper, Demapper\n",
    "from sionna.utils import BinarySource, compute_ber, BinaryCrossentropy\n",
    "from sionna.channel import AWGN\n",
    "from sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\n",
    "\n",
    "# For the implementation of the neural receiver\n",
    "import tensorflow as tf\n",
    "# Avoid warnings from TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow.keras.layers import Dense, Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebba48",
   "metadata": {},
   "source": [
    "Let us define the required transmitter and receiver components for the transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd37e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "n = 1000 # codeword length\n",
    "k = 500 # information bits per codeword\n",
    "m = 4 # number of bits per symbol\n",
    "snr = 10\n",
    "\n",
    "c = Constellation(\"qam\", m)\n",
    "b = BinarySource()([batch_size, k])\n",
    "u = LDPC5GEncoder(k, n)(b)\n",
    "x = Mapper(constellation=c)(u)\n",
    "y = AWGN()([x, 1/snr])\n",
    "llr = Demapper(\"app\", constellation=c)([y, 1/snr])\n",
    "b_hat = LDPC5GDecoder(LDPC5GEncoder(k, n))(llr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d277b0a",
   "metadata": {},
   "source": [
    "We can now directly calculate the simulated bit-error-rate (BER) for the whole batch of 1024 codewords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e879417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coded BER = 0.000\n"
     ]
    }
   ],
   "source": [
    "ber = compute_ber(b, b_hat)\n",
    "print(f\"Coded BER = {ber :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e3694",
   "metadata": {},
   "source": [
    "## Automatic Gradient Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112252d",
   "metadata": {},
   "source": [
    "One of the key advantages of Sionna is that components can be made trainable or replaced by neural networks. In the following example, we have made the [Constellation](https://nvlabs.github.io/sionna/api/mapping.html#constellation) trainable and replaced [Demapper](https://nvlabs.github.io/sionna/api/mapping.html#demapping) with a NeuralDemapper, which is just a neural network defined through [Keras](https://keras.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11839611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us define the Neural Demapper\n",
    "class NeuralDemapper(Layer):\n",
    "    def build(self, input_shape):\n",
    "        # Initialize the neural network layers\n",
    "        self._dense1 = Dense(16, activation=\"relu\")\n",
    "        self._dense2 = Dense(m)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y, no = inputs\n",
    "\n",
    "        # Stack noise variance, real and imaginary\n",
    "        # parts of each symbol. The input to the\n",
    "        # neural network is [Re(y_i), Im(y_i), no].\n",
    "        no = no*tf.ones(tf.shape(y))\n",
    "        llr = tf.stack([tf.math.real(y),\n",
    "                        tf.math.imag(y),\n",
    "                        no], axis=-1)\n",
    "\n",
    "        # Compute neural network output\n",
    "        llr = self._dense1(llr)\n",
    "        llr = self._dense2(llr)\n",
    "\n",
    "        # Reshape to [batch_size, n]\n",
    "        llr = tf.reshape(llr, [batch_size, -1])\n",
    "        return llr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c2b5d",
   "metadata": {},
   "source": [
    "Now, we can simply replace the *classical* demapper with the previously defined NeuralDemapper and set the Constellation object trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ca1c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of the Constellation:  tf.Tensor(\n",
      "[[-0.00329827 -0.00322376 -0.00074452  0.00339787 -0.00513376 -0.00157427\n",
      "   0.00207564  0.00579527 -0.00197416 -0.01357635  0.00363045 -0.00814517\n",
      "   0.00536535  0.00455021  0.0116162   0.00674398]\n",
      " [-0.00412695  0.00536264  0.00231561  0.00733877 -0.00158195  0.00073293\n",
      "   0.00541865  0.00879211 -0.0044257   0.00550126 -0.00092697  0.00692451\n",
      "  -0.00466044 -0.00021787 -0.00036102  0.00797399]], shape=(2, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape: # Watch gradients\n",
    "    c = Constellation(\"qam\", m, trainable=True) # Constellation object is now trainable\n",
    "    b = BinarySource()([batch_size, k])\n",
    "    u = LDPC5GEncoder(k, n)(b)\n",
    "    x = Mapper(constellation=c)(u)\n",
    "    y = AWGN()([x, 1/snr])\n",
    "    llr = NeuralDemapper()([y, 1/snr]) # Replaced by the NeuralDemapper\n",
    "    loss = BinaryCrossentropy(from_logits=True)(u, llr)\n",
    "\n",
    "# Use TensorFlows automatic gradient computation\n",
    "grad = tape.gradient(loss, tape.watched_variables())\n",
    "\n",
    "print(\"Gradients of the Constellation object: \", grad[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d59b2",
   "metadata": {},
   "source": [
    "We could now use these gradients to write a custom training loop to jointly update the Constellation and the NeuralDemapper. For further details, we refer to the [Sionna Tutorial Part 2](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html) Jupyter notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
