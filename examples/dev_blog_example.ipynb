{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01e3f8f",
   "metadata": {},
   "source": [
    "# “Hello, Sionna!\"\n",
    "\n",
    "The following notebook implements the “Hello, Sionna!” example from the [Sionna whitepaper](https://arxiv.org/pdf/2203.11854.pdf) and the [NVIDIA blog post](https://developer.nvidia.com/blog/jumpstarting-link-level-simulations-with-sionna/). \n",
    "The transmission of a batch of LDPC codewords over an AWGN channel using 16QAM modulation is simulated. This example shows how Sionna layers are instantiated and applied to a previously defined tensor. The coding style follows the [functional API](https://www.tensorflow.org/guide/keras/functional) of Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f9e3c",
   "metadata": {},
   "source": [
    "The [official documentation](https://nvlabs.github.io/sionna) provides key material on how to use Sionna and how its components are implemented.\n",
    "Many more [tutorials](https://nvlabs.github.io/sionna/tutorials.html) are available online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7121a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T14:37:20.159201Z",
     "iopub.status.busy": "2024-09-26T14:37:20.158991Z",
     "iopub.status.idle": "2024-09-26T14:37:22.745946Z",
     "shell.execute_reply": "2024-09-26T14:37:22.745111Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0 # Use \"\" to use the CPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Import Sionna\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna\n",
    "    \n",
    "# IPython \"magic function\" for inline plots\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import required Sionna components\n",
    "from sionna.mapping import Constellation, Mapper, Demapper\n",
    "from sionna.utils import BinarySource, compute_ber, BinaryCrossentropy\n",
    "from sionna.channel import AWGN\n",
    "from sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\n",
    "\n",
    "# For the implementation of the neural receiver\n",
    "import tensorflow as tf\n",
    "# Avoid warnings from TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from tensorflow.keras.layers import Dense, Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebba48",
   "metadata": {},
   "source": [
    "Let us define the required transmitter and receiver components for the transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd37e0e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T14:37:22.748492Z",
     "iopub.status.busy": "2024-09-26T14:37:22.748175Z",
     "iopub.status.idle": "2024-09-26T14:37:27.121952Z",
     "shell.execute_reply": "2024-09-26T14:37:27.121203Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "n = 1000 # codeword length\n",
    "k = 500 # information bits per codeword\n",
    "m = 4 # number of bits per symbol\n",
    "snr = 10\n",
    "\n",
    "c = Constellation(\"qam\", m)\n",
    "b = BinarySource()([batch_size, k])\n",
    "u = LDPC5GEncoder(k, n)(b)\n",
    "x = Mapper(constellation=c)(u)\n",
    "y = AWGN()([x, 1/snr])\n",
    "llr = Demapper(\"app\", constellation=c)([y, 1/snr])\n",
    "b_hat = LDPC5GDecoder(LDPC5GEncoder(k, n))(llr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d277b0a",
   "metadata": {},
   "source": [
    "We can now directly calculate the simulated bit-error-rate (BER) for the whole batch of 1024 codewords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e879417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T14:37:27.125616Z",
     "iopub.status.busy": "2024-09-26T14:37:27.125466Z",
     "iopub.status.idle": "2024-09-26T14:37:27.133500Z",
     "shell.execute_reply": "2024-09-26T14:37:27.132903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coded BER = 0.000\n"
     ]
    }
   ],
   "source": [
    "ber = compute_ber(b, b_hat)\n",
    "print(f\"Coded BER = {ber :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e3694",
   "metadata": {},
   "source": [
    "## Automatic Gradient Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112252d",
   "metadata": {},
   "source": [
    "One of the key advantages of Sionna is that components can be made trainable or replaced by neural networks. In the following example, we have made the [Constellation](https://nvlabs.github.io/sionna/api/mapping.html#constellation) trainable and replaced [Demapper](https://nvlabs.github.io/sionna/api/mapping.html#demapping) with a NeuralDemapper, which is just a neural network defined through [Keras](https://keras.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11839611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T14:37:27.136134Z",
     "iopub.status.busy": "2024-09-26T14:37:27.135991Z",
     "iopub.status.idle": "2024-09-26T14:37:27.139761Z",
     "shell.execute_reply": "2024-09-26T14:37:27.139219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let us define the Neural Demapper\n",
    "class NeuralDemapper(Layer):\n",
    "    def build(self, input_shape):\n",
    "        # Initialize the neural network layers\n",
    "        self._dense1 = Dense(16, activation=\"relu\")\n",
    "        self._dense2 = Dense(m)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y, no = inputs\n",
    "\n",
    "        # Stack noise variance, real and imaginary\n",
    "        # parts of each symbol. The input to the\n",
    "        # neural network is [Re(y_i), Im(y_i), no].\n",
    "        no = no*tf.ones(tf.shape(y))\n",
    "        llr = tf.stack([tf.math.real(y),\n",
    "                        tf.math.imag(y),\n",
    "                        no], axis=-1)\n",
    "\n",
    "        # Compute neural network output\n",
    "        llr = self._dense1(llr)\n",
    "        llr = self._dense2(llr)\n",
    "\n",
    "        # Reshape to [batch_size, n]\n",
    "        llr = tf.reshape(llr, [batch_size, -1])\n",
    "        return llr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c2b5d",
   "metadata": {},
   "source": [
    "Now, we can simply replace the *classical* demapper with the previously defined NeuralDemapper and set the Constellation object trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ca1c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-26T14:37:27.142029Z",
     "iopub.status.busy": "2024-09-26T14:37:27.141897Z",
     "iopub.status.idle": "2024-09-26T14:37:27.779435Z",
     "shell.execute_reply": "2024-09-26T14:37:27.778664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of the Constellation object:  tf.Tensor(\n",
      "[[-0.0009651   0.0025867  -0.0043383   0.00211876 -0.00203735  0.00861313\n",
      "  -0.00309125  0.0054731   0.00067105 -0.00107028  0.00486547  0.00384407\n",
      "  -0.00064585  0.00644257  0.00148639  0.00458461]\n",
      " [ 0.0007507   0.00204241  0.00608814  0.00389569  0.00437382 -0.00785731\n",
      "   0.00848579 -0.00567978 -0.00811444 -0.00339919 -0.00613963 -0.00025632\n",
      "   0.00393356 -0.00667848  0.00480597 -0.00085825]], shape=(2, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape: # Watch gradients\n",
    "    c = Constellation(\"qam\", m, trainable=True) # Constellation object is now trainable\n",
    "    b = BinarySource()([batch_size, k])\n",
    "    u = LDPC5GEncoder(k, n)(b)\n",
    "    x = Mapper(constellation=c)(u)\n",
    "    y = AWGN()([x, 1/snr])\n",
    "    llr = NeuralDemapper()([y, 1/snr]) # Replaced by the NeuralDemapper\n",
    "    loss = BinaryCrossentropy(from_logits=True)(u, llr)\n",
    "\n",
    "# Use TensorFlows automatic gradient computation\n",
    "grad = tape.gradient(loss, tape.watched_variables())\n",
    "\n",
    "print(\"Gradients of the Constellation object: \", grad[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d59b2",
   "metadata": {},
   "source": [
    "We could now use these gradients to write a custom training loop to jointly update the Constellation and the NeuralDemapper. For further details, we refer to the [Sionna Tutorial Part 2](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html) Jupyter notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
